#using trained model to generate embeddings and perform Random Forest regression
#

from model import DMPNN
from sklearn.ensemble import RandomForestRegressor
import numpy as np
import pandas as pd
import torch
import matplotlib.pyplot as plt
import seaborn as sns

def load_model(model_path):
    """
    Load the pre-trained model
    Args:
    - model_path: str, path to the pre-trained model

    Returns:
    - model: MPNN, pre-trained model encoder gnn part
    """
    model = DMPNN(node_in_feats=8, edge_in_feats=4, node_out_feats=64, edge_hidden_feats=128, num_step_message_passing=6)
    model.load_state_dict(torch.load(model_path))
    model.eval()
    return model

def load_data(data_path):
    """
    Load the data
    Args:
    - data_path: str, path to the data

    Returns:
    - data: pd.DataFrame, data
    """
    data = pd.read_csv(data_path)
    return data

def generate_embeddings(model, smiles_list):
    """
    Generate molecule embeddings using the DMPNN model
    Args:
    - model: MPNN, pre-trained model
    - smiles_list: list, list of SMILES strings

    Returns:
    - embeddings: torch.Tensor, molecule embeddings generated by the model
    """
    embeddings = []
    for smiles in smiles_list:
        with torch.no_grad():
            pred = model(smiles)
            embeddings.append(pred)
    embeddings = torch.cat(embeddings, dim=0)
    return embeddings.numpy()


def random_forest_regression(embeddings, y):
    """
    Perform Random Forest Regression on the molecule embeddings
    Args:
    - embeddings: numpy.ndarray, molecule embeddings generated by the model/ pd.DataFrame
    - y: numpy.ndarray, target values

    Returns:
    - rf: RandomForestRegressor, Random Forest Regression model
    """
    rf = RandomForestRegressor(n_estimators=128)
    rf.fit(embeddings, y)
    return rf

def test_model(rf,test_embeddings):
    """
    Test the Random Forest Regression model
    Args:
    - rf: RandomForestRegressor, Random Forest Regression model
    - test_embeddings: numpy.ndarray, molecule embeddings generated by the model/ pd.DataFrame

    Returns:
    - mean: numpy.ndarray, mean of the predictions
    - std: numpy.ndarray, standard deviation of the predictions
    """
    all_preds = np.stack([estimator.predict(test_embeddings) for estimator in rf.estimators_], axis=0)
    mean = np.mean(all_preds, axis=0)
    std = np.std(all_preds, axis=0)
    return mean, std

def evaluate_result(mean, std, y):
    """
    Evaluate the results and 
    Args:
    - mean: numpy.ndarray, mean of the predictions
    - std: numpy.ndarray, standard deviation of the predictions
    - y: numpy.ndarray, target values

    Returns:
    - rmse: float, root mean squared error
    - spearman: float, Spearman correlation rank to evaluate the relationship between rmse and std
    - nll: float, negative log likelihood
    - cnll : float, calibrated negative log likelihood
    """
    rmse = np.sqrt(np.mean((mean - y) ** 2))
    spearman = np.corrcoef(np.stack([mean, std], axis=0))[0, 1]
    nll = np.mean(-np.log(np.exp(-0.5 * ((mean - y) / std) ** 2) / (np.sqrt(2 * np.pi) * std)))
    cnll = np.mean(-np.log(np.exp(-0.5 * ((mean - y) / std) ** 2) / (np.sqrt(2 * np.pi) * std)))
    return rmse, spearman, nll, cnll

def plot_result_spearman(rmse, spearman):
    """
    Plot the result
    Args:
    - rmse: float, root mean squared error
    - spearman: float, Spearman correlation
    """
    sns.scatterplot(x=rmse, y=spearman)
    plt.xlabel('RMSE')
    plt.ylabel('Spearman')
    plt.show()

    


def main(model_path, data_path, test_data_path):
    model = load_model(model_path)
    data = load_data(data_path)
    test_data = load_data(test_data_path)
    smiles_list = data['smiles'].tolist()
    test_smiles_list = test_data['smiles'].tolist()
    embeddings = generate_embeddings(model, smiles_list)
    y = data['target'].values
    rf = random_forest_regression(embeddings, y)
    test_embeddings = generate_embeddings(model, test_smiles_list)
    mean, std = test_model(rf, test_embeddings)
    return mean, std