#!/cluster/home/hsu02/.conda/envs/hfe/bin/python
#SBATCH --job-name=MPNNGP
#SBATCH --output=MPNNGP.out
#SBATCH --error=MPNNGP.err
#SBATCH --time=1-00:00:00
#SBATCH --cpus-per-task=10
#SBATCH --mem=64G
#SBATCH --gres=gpu:1
#SBATCH --partition=dinglab



#using trained model to generate embeddings and perform Gaussian Process regression
import sys
sys.path.append('/cluster/tufts/dinglab/hsu02/code/DMPNN')
sys.path.append('/cluster/tufts/dinglab/hsu02/code')
import os
from model import MPNNEncoder
from torch_geometric.data import Data
from dataset import mol_to_graph
import GPy
import numpy as np
import pandas as pd
from rdkit import Chem
import torch
import matplotlib.pyplot as plt
import seaborn as sns


def load_model(model_path):
    """
    Load the pre-trained model
    Args:
    - model_path: str, path to the pre-trained model

    Returns:
    - model: MPNN, pre-trained model encoder gnn part
    """
    model = MPNNEncoder(node_in_feats=8, edge_in_feats=4, node_out_feats=256, edge_hidden_feats=256, num_step_message_passing=6)
    state_dict = torch.load(model_path)
    model.load_state_dict(state_dict,strict=False)

    return model


def load_data(data_path,split_ratio=0.8,random_seed=114):
    """
    Load the data and split it into training and testing sets
    Load the data and split it into training and testing sets
    Args:
    - data_path: str, path to the data

    Returns:
    - train_data: pd.DataFrame, training data
    - test_data: pd.DataFrame, testing data

    """
    data = pd.read_csv(data_path)
    train_data = data.sample(frac=split_ratio, random_state=random_seed)
    test_data = data.drop(train_data.index)

    return train_data, test_data
    

def generate_embeddings(model, smiles_list):
    """
    Generate molecule embeddings using the DMPNN model
    Args:
    - model: MPNN, pre-trained model
    - smiles_list: list, list of SMILES strings

    Returns:
    - embeddings: numpy.ndarray, molecule embeddings generated by the model
    """
    embeddings = []
    for smiles in smiles_list:
        mol = Chem.MolFromSmiles(smiles)
        x, edge_index, edge_attr = mol_to_graph(mol=mol)
        x = torch.tensor(x, dtype=torch.float)
        edge_index = torch.tensor(edge_index, dtype=torch.long)
        edge_attr = torch.tensor(edge_attr, dtype=torch.float)
        data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)
        mol = Chem.MolFromSmiles(smiles)
        x, edge_index, edge_attr = mol_to_graph(mol=mol)
        x = torch.tensor(x, dtype=torch.float)
        edge_index = torch.tensor(edge_index, dtype=torch.long)
        edge_attr = torch.tensor(edge_attr, dtype=torch.float)
        data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)
        with torch.no_grad():
            pred = model(data).detach()
            embeddings.append(pred)
    embeddings = torch.cat(embeddings, dim=0)
    return embeddings.numpy()


def SparseGPRegression(train_embeddings, train_y):
    """
    Train the Sparse Gaussian Process Regression model
    Args:
    - train_embeddings: numpy.ndarray, molecule embeddings generated by the model
    - train_y: pandas.Series, target values

    Returns:
    - gp: GPy.models.GPRegression, trained Sparse Gaussian Process Regression model
    """
    gp = GPy.models.SparseGPRegression(train_embeddings, train_y.values.reshape(-1, 1), num_inducing=100)
    gp.optimize()
    return gp

def test_model(gp, test_embeddings):
    """
    Test the Sparse Gaussian Process Regression model
    Args:
    - gp: GPy.models.GPRegression, trained Sparse Gaussian Process Regression model
    - test_embeddings: numpy.ndarray, molecule embeddings generated by the model

    Returns:
    - mean: numpy.ndarray, mean of the predictions
    - std: numpy.ndarray, standard deviation of the predictions
    """
    mean, var = gp.predict(test_embeddings)
    std = np.sqrt(var)
    return mean, std

def evaluate_result(mean, std, y):
    """
    Evaluate the results and 
    Args:
    - mean: numpy.ndarray, mean of the predictions
    - std: numpy.ndarray, standard deviation of the predictions
    - y: pandas.Series, target values

    Returns:
    - abs_error: numpy.ndarray, absolute error for each prediction
    - nll: numpy.ndarray, negative log likelihood for each prediction

    """
    abs_error = np.abs(mean - y)
    nlls = []
    for _ in range(len(mean)):
        nll = 0.5 * np.log(2 * np.pi * std[_] ** 2) + 0.5 * ((mean[_] - y.iloc[_]) / std[_]) ** 2
        nlls.append(nll)
  

    nlls = np.array(nlls)

    return  abs_error, nlls

def plot_result(mean, std, y, savename):
    """
    Plot the results
    Args:
    - mean: numpy.ndarray, mean of the predictions
    - std: numpy.ndarray, standard deviation of the predictions
    - y: numpy.ndarray, target values
    - savename: str, name to save the plot
    """
    plt.figure(figsize=(10, 10))
    sns.scatterplot(x=y, y=mean)
    plt.errorbar(x=y, y=mean, yerr=std, fmt='o',ecolor='r',color='b')
    plt.plot([min(y), max(y)], [min(y), max(y)], 'k--')
    plt.legend(['y=x', 'prediction', 'error'])
    plt.xlabel('True')
    plt.ylabel('Predicted')
    plt.savefig(f'plot_result_gp_{savename}.png')

def plot_rmse_std_relation(abs_error, std, savename):
    """
    Plot the relationship between  abs_error and STD
    Args:
    - abs_error: numpy.ndarray, absolute error for each prediction
    - std: numpy.ndarray, standard deviation of the predictions
    - savename: str, name to save the plot
    """
    plt.figure(figsize=(10, 10))
    sns.scatterplot(x=abs_error, y=std,palette='viridis',hue=std)
    # plot linear regression line
    plt.plot(np.unique(abs_error), np.poly1d(np.polyfit(abs_error, std, 1))(np.unique(abs_error)), color='#EE0000')
    # plot r2 score
    plt.text(0.1, 0.9, f'R2 score: {np.corrcoef(abs_error, std)[0, 1] ** 2:.4f}', ha='center', va='center', transform=plt.gca().transAxes)
    plt.xlabel('ABS Error')
    plt.ylabel('STD')
    plt.savefig(f'plot_rmse_std_relation_gp_{savename}.png')

def plot_rmse_nll_relation(rmse, nll, savename):
    """
    Plot the relationship between RMSE and NLL
    Args:
    - rmse: numpy.ndarray, root mean squared error for each prediction
    - nll: numpy.ndarray, negative log likelihood for each prediction
    - savename: str, name to save the plot
    """
    plt.figure(figsize=(10, 10))
    sns.scatterplot(x=rmse, y=nll,palette='viridis')
    # plot linear regression line
    plt.plot(np.unique(rmse), np.poly1d(np.polyfit(rmse, nll, 1))(np.unique(rmse)), color='#EE0000')
    # plot r2 score
    plt.text(0.1, 0.9, f'R2 score: {np.corrcoef(rmse, nll)[0, 1] ** 2:.4f}', ha='center', va='center', transform=plt.gca().transAxes)
    plt.xlabel('abs_error')
    plt.ylabel('NLL')
    plt.savefig(f'plot_rmse_nll_relation_gp_{savename}.png')

def nll_boxplot(nll,save_name):
    """
    Plot the boxplot of NLL
    Args:
    - nll: numpy.ndarray, negative log likelihood for each prediction
    - save_name: str, name to save the plot
    """
    plt.figure(figsize=(10, 10))
    sns.boxplot(nll)
    plt.xlabel('NLL')
    plt.savefig(f'nll_boxplot_gp_{save_name}.png')

def main(model_path, data_path):
    """
    Main function
    Args:
    - model_path: str, path to the pre-trained model
    - data_path: str, path to the data
    """
    model = load_model(model_path)
    train_data, test_data = load_data(data_path)
    train_embeddings = generate_embeddings(model, train_data['smiles'])
    test_embeddings = generate_embeddings(model, test_data['smiles'])

    gp = SparseGPRegression(train_embeddings, train_data['expt'])
    # get train results first
    mean, std = test_model(gp, train_embeddings)
    mean = mean.flatten()
    std = std.flatten()
    rmse, nll = evaluate_result(mean, std, train_data['expt'])
    plot_result(mean, std, train_data['expt'],'train')
    plot_rmse_std_relation(rmse, std,'train')
    plot_rmse_nll_relation(rmse, nll,'train')
    nll_boxplot(nll,'train')

    #write train results to file
    train_data['pred'] = mean
    train_data['std'] = std
    train_data['rmse'] = rmse
    train_data['nll'] = nll
    train_data.to_csv('train_results_gp.csv')

    # get test results
    mean, std = test_model(gp, test_embeddings)
    mean = mean.flatten()
    std = std.flatten()
    rmse, nll = evaluate_result(mean, std, test_data['expt'])
    plot_result(mean, std, test_data['expt'],'test')
    plot_rmse_std_relation(rmse, std,'test')
    plot_rmse_nll_relation(rmse, nll,'test')
    nll_boxplot(nll,'test')

    #write test results to file
    test_data['pred'] = mean
    test_data['std'] = std
    test_data['rmse'] = rmse
    test_data['nll'] = nll
    test_data.to_csv('test_results_gp.csv')
    

if __name__ == '__main__':
    root_path = '/cluster/tufts/dinglab/hsu02/code/'
    model_path = 'model.pth'
    data_path = root_path + 'data/FreeSolv/raw/freesolv.csv'
    main(model_path, data_path)
    