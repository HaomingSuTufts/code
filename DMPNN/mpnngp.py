#using trained model to generate embeddings and perform Gaussian Process regression


from model import MPNNEncoder
from torch_geometric.data import Data
from dataset import mol_to_graph
from GPy import GPRegression
import numpy as np
import pandas as pd
from rdkit import Chem
import torch
import matplotlib.pyplot as plt
import seaborn as sns

def load_model(model_path):
    """
    Load the pre-trained model
    Args:
    - model_path: str, path to the pre-trained model

    Returns:
    - model: MPNN, pre-trained model encoder gnn part
    """
    model = MPNNEncoder(node_in_feats=8, edge_in_feats=4, node_out_feats=256, edge_hidden_feats=256, num_step_message_passing=6)
    state_dict = torch.load(model_path)
    model.load_state_dict(state_dict,strict=False)

    return model

def load_data(data_path,split_ratio=0.8,random_seed=0):
    """
    Load the data and split it into training and testing sets
    Args:
    - data_path: str, path to the data

    Returns:
    - train_data: pd.DataFrame, training data
    - test_data: pd.DataFrame, testing data

    """
    data = pd.read_csv(data_path)
    train_data = data.sample(frac=split_ratio, random_state=random_seed)
    test_data = data.drop(train_data.index)

    return train_data, test_data
    

def generate_embeddings(model, smiles_list):
    """
    Generate molecule embeddings using the DMPNN model
    Args:
    - model: MPNN, pre-trained model
    - smiles_list: list, list of SMILES strings

    Returns:
    - embeddings: numpy.ndarray, molecule embeddings generated by the model
    """
    embeddings = []
    for smiles in smiles_list:
        mol = Chem.MolFromSmiles(smiles)
        x, edge_index, edge_attr = mol_to_graph(mol=mol)
        x = torch.tensor(x, dtype=torch.float)
        edge_index = torch.tensor(edge_index, dtype=torch.long)
        edge_attr = torch.tensor(edge_attr, dtype=torch.float)
        data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)
        with torch.no_grad():
            pred = model(data).detach()
            embeddings.append(pred)
    embeddings = torch.cat(embeddings, dim=0)
    return embeddings.numpy()


def random_forest_regression(embeddings, y):
    """
    Perform Random Forest Regression on the molecule embeddings
    Args:
    - embeddings: numpy.ndarray, molecule embeddings generated by the model/ pd.DataFrame
    - y: numpy.ndarray, target values

    Returns:
    - rf: RandomForestRegressor, Random Forest Regression model
    """
    rf = RandomForestRegressor(n_estimators=128)
    rf.fit(embeddings, y)
    return rf

def test_model(rf,test_embeddings):
    """
    Test the Random Forest Regression model
    Args:
    - rf: RandomForestRegressor, Random Forest Regression model
    - test_embeddings: numpy.ndarray, molecule embeddings generated by the model/ pd.DataFrame

    Returns:
    - mean: numpy.ndarray, mean of the predictions
    - std: numpy.ndarray, standard deviation of the predictions
    """
    all_preds = np.stack([estimator.predict(test_embeddings) for estimator in rf.estimators_], axis=0)
    mean = np.mean(all_preds, axis=0)
    std = np.std(all_preds, axis=0)
    return mean, std

def evaluate_result(mean, std, y):
    """
    Evaluate the results and 
    Args:
    - mean: numpy.ndarray, mean of the predictions
    - std: numpy.ndarray, standard deviation of the predictions
    - y: pandas.Series, target values

    Returns:
    - rmse: numpy.ndarray, root mean squared error for each prediction
    - nll: numpy.ndarray, negative log likelihood for each prediction
    - cnll: numpy.ndarray, calibrated negative log likelihood for each prediction
    """
    rmses = []
    nlls = []
    cnlls = []
    for _ in range(len(mean)):
        rmse = abs(mean[_] - y.iloc[_])
        nll = 0.5 * np.log(2 * np.pi * std[_] ** 2) + 0.5 * ((mean[_] - y.iloc[_]) / std[_]) ** 2
        cnll = nll - np.log(std[_])
        rmses.append(rmse)
        nlls.append(nll)
        cnlls.append(cnll)
    
    rmses = np.array(rmses)
    nlls = np.array(nlls)
    cnlls = np.array(cnlls)
    return rmses, nlls, cnlls

def plot_result(mean, std, y):
    """
    Plot the results
    Args:
    - mean: numpy.ndarray, mean of the predictions
    - std: numpy.ndarray, standard deviation of the predictions
    - y: numpy.ndarray, target values
    """
    plt.figure(figsize=(10, 10))
    sns.scatterplot(x=y, y=mean)
    plt.errorbar(x=y, y=mean, yerr=std, fmt='o')
    plt.plot([min(y), max(y)], [min(y), max(y)], 'k--')
    plt.xlabel('True')
    plt.ylabel('Predicted')
    plt.show()

def plot_rmse_std_relation(rmse, std):
    """
    Plot the relationship between RMSE and STD
    Args:
    - rmse: numpy.ndarray, root mean squared error for each prediction
    - std: numpy.ndarray, standard deviation of the predictions
    """
    plt.figure(figsize=(10, 10))
    sns.scatterplot(x=rmse, y=std)
    plt.xlabel('RMSE')
    plt.ylabel('STD')
    plt.show()

def plot_rmse_nll_relation(rmse, nll):
    """
    Plot the relationship between RMSE and NLL
    Args:
    - rmse: numpy.ndarray, root mean squared error for each prediction
    - nll: numpy.ndarray, negative log likelihood for each prediction
    """
    plt.figure(figsize=(10, 10))
    sns.scatterplot(x=rmse, y=nll)
    plt.xlabel('RMSE')
    plt.ylabel('NLL')
    plt.show()

def nll_boxplot(nll):
    """
    Plot the boxplot of NLL
    Args:
    - nll: numpy.ndarray, negative log likelihood for each prediction
    """
    plt.figure(figsize=(10, 10))
    sns.boxplot(nll)
    plt.show()

def main(model_path, data_path):
    """
    Main function
    Args:
    - model_path: str, path to the pre-trained model
    - data_path: str, path to the data
    """
    model = load_model(model_path)
    train_data, test_data = load_data(data_path)
    train_embeddings = generate_embeddings(model, train_data['smiles'])
    test_embeddings = generate_embeddings(model, test_data['smiles'])

    rf = random_forest_regression(train_embeddings, train_data['expt'])
    mean, std = test_model(rf, train_embeddings)


    rmse, nll, cnll = evaluate_result(mean, std, train_data['expt'])

    plot_result(mean, std, train_data['expt'])
    plot_rmse_std_relation(rmse, std)
    plot_rmse_nll_relation(rmse, nll)
    nll_boxplot(nll)

    result = pd.DataFrame({'smiles': train_data['smiles'], 'expt': train_data['expt'], 'mean': mean, 'std': std, 'rmse': rmse, 'nll': nll, 'cnll': cnll})
    result.to_csv('result1.csv', index=False)

if __name__ == '__main__':
    root_path = ''
    model_path = 'model.pth'
    data_path = root_path + 'data/FreeSolv/raw/FreeSolv.csv'
    main(model_path, data_path)
    